{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcSBIUP1yeyTkGuXBoV/6P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SorrowAddict/SK-FLY-AI/blob/main/240130_LangChain_02_prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNSH75GjFlsd",
        "outputId": "d4fcba0e-29f2-49d9-86fe-306a92e9d6ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.1/225.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.14)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing-extensions, h11, httpcore, httpx, openai\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 openai-1.10.0 typing-extensions-4.9.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
            "  Downloading langchain_core-0.1.17-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, langsmith, jsonpatch, langchain-core, dataclasses-json, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.17 langsmith-0.0.84 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '3a9d04966a3c43ca92de7be4b803d6f7'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://skyfly-001.openai.azure.com/'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'"
      ],
      "metadata": {
        "id": "XvDtcw-cF8xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import AzureOpenAI\n",
        "from langchain.chat_models import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "XLP0qSDhF-9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = AzureOpenAI(\n",
        "    deployment_name='dev-gpt-35-turbo-instruck',\n",
        "    max_tokens=1000     # 최대 토큰 제한 (비용 감축)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOB5FTvyGHEC",
        "outputId": "5194bf43-db62-4ebd-f20b-616f1a1631d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.AzureOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
        "\n",
        "string_prompt = PromptTemplate.from_template('tell me a joke about {subject}')\n",
        "string_prompt_value = string_prompt.format_prompt(subject='soccer')     # subject를 바꿔 낄 때마다 주제변경 가능 (코드의 체계화)\n",
        "\n",
        "string_prompt_value.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "P2JP6tkFGO8I",
        "outputId": "d57ee93e-3958-4c68-bc8c-d34b482c2b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tell me a joke about soccer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = '''\n",
        "너는 요리사야. 내가 갖고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\n",
        "내가 가진 재료는 아래와 같아\n",
        "\n",
        "<재료>\n",
        "{재료}\n",
        "'''"
      ],
      "metadata": {
        "id": "pmiXadXCHzHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=['재료'],\n",
        "    template = template\n",
        ")\n",
        "\n",
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXsq5VOiIbLV",
        "outputId": "be188c60-a351-4ffe-9190-421455f9bda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['재료'], template='\\n너는 요리사야. 내가 갖고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\\n내가 가진 재료는 아래와 같아\\n\\n<재료>\\n{재료}\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.format(재료='양파,계란,사과,빵')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bOE2IuVJIfga",
        "outputId": "4337877b-57d9-4c13-f5ce-3f190d694d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n너는 요리사야. 내가 갖고 있는 재료들로 만들 수 있는 요리를 추천하고 그 요리의 레시피를 제시해\\n내가 가진 재료는 아래와 같아\\n\\n<재료>\\n양파,계란,사과,빵\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt_template.format(재료='양파,계란,사과,빵'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "iaEPSUGyIfeD",
        "outputId": "aa937024-4da4-44e8-cf20-3aedbed01ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n추천 요리: 계란말이 샌드위치\\n\\n<레시피>\\n1. 양파를 채 썰어 준비한다.\\n2. 계란을 깨서 풀어서 양파에 넣어 볶아준다.\\n3. 계란이 익으면 빵 한 조각 위에 양파 계란 볶음을 올려준다.\\n4. 사과를 얇게 썰어 빵 위에 올려준다.\\n5. 다른 빵 한 조각을 덮어 샌드위치를 만들어준다.\\n6. 팬에 버터를 녹여 샌드위치를 구워준다.\\n7. 구워진 샌드위치를 접시에 담고 저으음즈를 넣어 서빙한다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 대화형 모델의 템플릿\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate\n",
        ")\n",
        "\n",
        "from langchain.schema import(\n",
        "    SystemMessage,\n",
        "    AIMessage,\n",
        "    HumanMessage\n",
        ")"
      ],
      "metadata": {
        "id": "okT-ggYuIfby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatgpt = AzureChatOpenAI(deployment_name='dev-gpt-35-turbo', temperature=0)\n",
        "\n",
        "# 시스템 메시지 프롬프트의 설정\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "\n",
        "# 휴먼 메시지 프롬프트의 설정\n",
        "human_template = '{재료}'\n",
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "\n",
        "# 챗 프롬프트 템플릿\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt,\n",
        "                                                human_message_prompt])\n",
        "\n",
        "answer = chatgpt(chat_prompt.format_prompt(재료='밀가루,계란,치즈,케찹').to_messages())\n",
        "print(answer.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCjwRtMAIfZ3",
        "outputId": "2a54adfc-4220-4ae8-eff7-038486f9f547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "재료로 만들 수 있는 요리 중 하나는 \"치즈 팬케이크\"입니다. 아래는 치즈 팬케이크의 레시피입니다.\n",
            "\n",
            "[치즈 팬케이크 레시피]\n",
            "1. 밀가루 1컵을 그릇에 넣고, 계란 1개와 물 1/2컵을 함께 넣어서 고루 섞어줍니다.\n",
            "2. 치즈 1/2컵을 다진 후, 팬케이크 반죽에 넣고 섞어줍니다.\n",
            "3. 팬을 달구고 중간 불로 예열한 후, 팬케이크 반죽을 한 국자씩 떠서 팬에 올려줍니다.\n",
            "4. 팬케이크가 골드 브라운으로 익을 때까지 약 2분씩 구워줍니다.\n",
            "5. 팬케이크를 뒤집어 반대편도 골드 브라운으로 익힌 후, 접시에 옮겨줍니다.\n",
            "6. 케찹을 곁들여서 맛있게 즐겨보세요!\n",
            "\n",
            "치즈 팬케이크는 부드럽고 고소한 치즈와 밀가루의 조합으로 만들어지며, 케찹을 더해 더욱 맛있게 즐길 수 있습니다. 쉽고 간단하게 만들 수 있으니, 한번 시도해보시기 바랍니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few shot learning\n",
        "\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        'question':'아이유로 삼행시를 지어줘',\n",
        "        'answer':'''\n",
        "        아 아이유는\n",
        "        이 이상하고\n",
        "        유 유난히 좋다.\n",
        "        '''\n",
        "    },\n",
        "    {\n",
        "        'question':'이순신으로 삼행시를 지어줘',\n",
        "        'answer':'''\n",
        "        이 이순신 장군은\n",
        "        순 순순히 내어줄 것 같았던 조선의 바다를\n",
        "        신 신의와 충의의 마음으로 지켜냈다.\n",
        "        '''\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "XWnLe_wwIfXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 템플릿을 제작\n",
        "example_prompt = PromptTemplate(input_variables=['question','answer'],\n",
        "                                template='Question: {question}\\n{answer}')\n",
        "\n",
        "# 샘플 템플릿의 테스트\n",
        "print(example_prompt.format(**examples[0]))        # ** 없이는 오류"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSQvXWcxIfVK",
        "outputId": "c445dc51-b009-44d3-de2c-57fc813ec1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: 아이유로 삼행시를 지어줘\n",
            "\n",
            "        아 아이유는\n",
            "        이 이상하고\n",
            "        유 유난히 좋다.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Few Shot Learning을 위한 템플릿 제작\n",
        "prompt = FewShotPromptTemplate(\n",
        "            examples=examples,\n",
        "            example_prompt=example_prompt,\n",
        "            suffix='Question: {input}',\n",
        "            input_variables=['input']\n",
        ")"
      ],
      "metadata": {
        "id": "C-NPH_sbIfSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke('호날두로 삼행시를 지어줘'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEMyUx8NU6Ld",
        "outputId": "c849a52c-dd5c-40ac-da87-756ed4c4657c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "호날두가 큰 발로 걸어요\n",
            "멋진 발이 깃발처럼 휘날려요\n",
            "모두가 호날두 발 따라해요\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(input='정도영으로 삼행시를 지어줘')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f66q_-bvU6Ja",
        "outputId": "7ddc2e5f-6050-48e1-fc5f-4676f06ac0c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        정 정도영은\n",
            "        도 도전적인 모습으로\n",
            "        영 영원히 빛나고 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(input='채성원으로 삼행시를 부정적으로 지어줘')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqpzwayhost2",
        "outputId": "710fab0f-7e53-40da-bb89-40a9390c65f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        채 채성원의 시는\n",
            "        성 성의 없어 보이고\n",
            "        원 원하는 바를 찾지 못하네.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(input='양성우로 삼행시를 지어줘')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WozaXGihonik",
        "outputId": "cfa6ac0a-df14-4ec6-d11c-a15036b2e52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "        양 양성우는\n",
            "        성 성실하고\n",
            "        우 우아하게 늘 빛난다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 템플릿을 어떻게 하면 잘 짤까... 언어모델을 어떤 걸 쓸까"
      ],
      "metadata": {
        "id": "Gshy60zcU6HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOdXdFkOIfGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Test Code"
      ],
      "metadata": {
        "id": "i_Rct217U3Yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import langchain\n",
        "\n",
        "# Azure개발 모델 개발, davinci-002사용해봄, dev-davinci-002\n",
        "os.environ['OPENAI_API_KEY'] = '3a9d04966a3c43ca92de7be4b803d6f7'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://skyfly-001.openai.azure.com/'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'\n",
        "\n",
        "from langchain.llms import AzureOpenAI\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    deployment_name='dev-gpt-35-turbo-instruct'\n",
        ")\n",
        "\n",
        "# 사례 fact부분 번역해서 넣으면됨\n",
        "sentence_eng = \"The accident occurred when the taxi driver opened the driver's seat door without properly checking the traffic situation while stopping in the no-parking zone, and collided with the right part of the plaintiff's vehicle driving along the five lanes. However, the accident site is a place where taxis usually stop in a row to pick up passengers leaving Busan Station, and many taxis were stopping in a row on the right edge of the road even at the time of the accident. As a driver passing through these places, he or she is obligated to drive while closely watching the movement of the taxi that stopped to prevent an accident\"\n",
        "sentence_kor = \"택시 운전자가 주정차금지구역에 정차한 상태에서 교통상황을 제대로 확인하지 않은 채 운전석 문을 열면서, 5차로를 따라 주행하던 원고 차량 오른쪽 부분과 부딪히는 이 사건 사고가 발생하였다 다만 사고 장소는 평소 부산역에서 나오는 승객들을 태우기 위해 택시들이 일렬로 정차하는 장소로, 사고 당시에도 도로 우측 가장자리에 많은 택시가 줄지어 정차하고 있었다 이러한 장소를 지나가는 운전자로서는 사고를 미연에 방지하기 위하여 정차한 택시의 움직임을 예의 주시하면서 운전할 주의의무가 있다.\"\n",
        "\n",
        "# sentence 사례가 민사면 2, 형사면 1, 다 아니면 0\n",
        "answer_eng = llm.invoke('if sentence is possible to civil proceedings return 2 else if sentence possible to be criminally punished return 1 else return 0. the sentence : ' + sentence_eng)\n",
        "answer_kor = llm.invoke('if sentence is possible to civil proceedings return 2 else if sentence possible to be criminally punished return 1 else return 0. the sentence : ' + sentence_kor)\n",
        "\n",
        "print(answer_eng)\n",
        "print(answer_kor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNh1jRmCHFf4",
        "outputId": "22d60f1e-66bc-4612-c1de-2da71361e259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "return 2\n",
            "\n",
            "\n",
            "The sentence is possible to be criminally punished, therefore return 1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import langchain\n",
        "\n",
        "# 강의 내용 Azure개발 모델 개발, davinci-002사용해봄, dev-davinci-002\n",
        "os.environ['OPENAI_API_KEY'] = '3a9d04966a3c43ca92de7be4b803d6f7'\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = 'https://skyfly-001.openai.azure.com/'\n",
        "os.environ['OPENAI_API_TYPE'] = 'azure'\n",
        "os.environ['OPENAI_API_VERSION'] = '2023-05-15'\n",
        "\n",
        "from langchain.llms import AzureOpenAI\n",
        "\n",
        "llm = AzureOpenAI(\n",
        "    deployment_name='dev-gpt-35-turbo-instruct'\n",
        ")\n",
        "\n",
        "# 사례 fact부분 번역해서 넣으면됨\n",
        "sentence_eng = \"The accident occurred when the taxi driver opened the driver's seat door without properly checking the traffic situation while stopping in the no-parking zone, and collided with the right part of the plaintiff's vehicle driving along the five lanes. However, the accident site is a place where taxis usually stop in a row to pick up passengers leaving Busan Station, and many taxis were stopping in a row on the right edge of the road even at the time of the accident. As a driver passing through these places, he or she is obligated to drive while closely watching the movement of the taxi that stopped to prevent an accident\"\n",
        "sentence_kor = \"택시 운전자가 주정차금지구역에 정차한 상태에서 교통상황을 제대로 확인하지 않은 채 운전석 문을 열면서, 5차로를 따라 주행하던 원고 차량 오른쪽 부분과 부딪히는 이 사건 사고가 발생하였다 다만 사고 장소는 평소 부산역에서 나오는 승객들을 태우기 위해 택시들이 일렬로 정차하는 장소로, 사고 당시에도 도로 우측 가장자리에 많은 택시가 줄지어 정차하고 있었다 이러한 장소를 지나가는 운전자로서는 사고를 미연에 방지하기 위하여 정차한 택시의 움직임을 예의 주시하면서 운전할 주의의무가 있다.\"\n",
        "\n",
        "# sentence 사례가 민사면 2, 형사면 1, 다 아니면 0\n",
        "answer_eng = llm.invoke('if sentence is possible to civil proceedings return 2 else if sentence possible to be criminally punished return 1 else return 0 just say num. the sentence : ' + sentence_eng)\n",
        "answer_kor = llm.invoke('if sentence is possible to civil proceedings return 2 else if sentence possible to be criminally punished return 1 else return 0 just say num. the sentence : ' + sentence_kor)\n",
        "\n",
        "print(answer_eng)\n",
        "print(answer_kor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAWu3bftIRe2",
        "outputId": "3929a416-0080-4ddd-fa05-dab378d7e83f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1\n",
            "\n",
            "\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hu1fZw1nIShi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}